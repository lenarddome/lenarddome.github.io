<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Lenard  Dome | psp [aut, cre]</title>
<meta name="description" content="">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.xyz/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üî•</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/software/psp/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

  <script src="/assets/js/theme.js"></script>
  <!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Lenard</span>   Dome
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/software/">
                software
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      

<div class="post">

  <header class="post-header">
    <h1 class="post-title">psp [aut, cre]</h1>
    <p class="post-meta">July 5, 2021</p>
  </header>

  <article class="post-content">
    <p><a href="https://cran.r-project.org/package=psp"><img src="https://cranlogs.r-pkg.org/badges/grand-total/psp" height="20px" alt="" /></a>
<a href="https://cran.r-project.org/package=psp"><img src="https://img.shields.io/cran/v/psp" height="20px" alt="" /></a>
<a href="https://cran.r-project.org/package=psp"><img src="https://img.shields.io/cran/l/psp" height="20px" alt="" /></a></p>

<h2 id="implements-an-n-dimensional-parameter-space-partitioning-algorithm-for-evaluating-the-global-behaviour-of-formal-computational-models-as-described-by-pitt-kim-navarro-and-myung-2006">Implements an n-dimensional parameter space partitioning algorithm for evaluating the global behaviour of formal computational models as described by <a href="https://psycnet.apa.org/doiLanding?doi=10.1037/0033-295X.113.1.57">Pitt, Kim, Navarro and Myung (2006)</a></h2>

<p><br /></p>

<div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet" align="center"><p lang="en" dir="ltr">My first <a href="https://twitter.com/hashtag/rstats?src=hash&amp;ref_src=twsrc%5Etfw">#rstats</a> <a href="https://twitter.com/hashtag/rpackage?src=hash&amp;ref_src=twsrc%5Etfw">#rpackage</a> is out on CRAN!<br />The package implements a global qualitative <a href="https://twitter.com/hashtag/modelevaluation?src=hash&amp;ref_src=twsrc%5Etfw">#modelevaluation</a><br />tool as described by Pitt, Kim, Navarro and Myung (2006). It also works in n dimensions. :)<a href="https://t.co/XFVyyNgUoi">https://t.co/XFVyyNgUoi</a><br /><br />Give it a whirl with install.packages(&quot;psp&quot;)!</p>&mdash; L√©n√°rd D√∂me (@lenarddome) <a href="https://twitter.com/lenarddome/status/1407269362667560960?ref_src=twsrc%5Etfw">June 22, 2021</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>

<p><br /></p>

<p>2021-07-05T09:55:05+0100: THIS MANUAL IS IN DEVELOPMENT</p>

<h2 id="code-development">CODE DEVELOPMENT</h2>

<p>A big influence on this implementation is an instantiation of the Open Models
Initiative, <a href="https://github.com/ajwills72/catlearn">catlearn</a>.</p>

<p>Watch the talk of <a href="https://youtu.be/SfqkqEYagJU">Andy Wills: ‚ÄúThe OpenModels project‚Äù</a>
from Open Research Working Group (ORWG) virtual meeting 08/09/20.</p>

<p>The project‚Äôs architecture is also influenced by <a href="https://github.com/ArdiaD/DEoptim">DEoptim</a>.
<code class="language-plaintext highlighter-rouge">DEoptim</code> implements a Differential Evolutionary Optimization algorithm for
model-fitting.</p>

<p>We are completely open-source and free. Anyone can contribute. If you would
like to raise an issue or contribute code, use Github, message or email me
(@lenarddome).</p>

<h2 id="formal-modelling-philosophy">FORMAL MODELLING PHILOSOPHY</h2>

<p><strong>There is a great and concise <a href="https://www.andywills.info/2021-06-23-psp/">blog post</a>
about it by <a href="https://www.andywills.info/">Andy Wills</a></strong>, who helped me quite a bit
in understanding what psp is and how it works. He is also an author
on the package. His post makes some good points about the essence of parameter
space partitioning, but I thought that I would reiterate and elaborate on some
of his points here and provide a manual.</p>

<p>Let us start from the beginning.
Formal models are theories that we have specified by  using some formal language like
maths <a href="https://doi.org/10.1177/1745691620970585">(Guest &amp; Martin, 2021)</a>.
These models also need to be implemented (programmed), which builds another layer
of assumptions as a result of engineering work <a href="https://doi.org/10.1016/j.cogsys.2013.05.001">(Cooper &amp; Guest, 2014)</a>.</p>

<p>There could be many specification of a single theory and multiple implementations
of a single specification.
The point here is that formal models describe theories and allow us to
formally generate a prediction of a given theory with high degree of precision.
If a model cannot capture a phenomenon observed under certain conditions, but
was designed to explain the phenomenon itself, we can say the model failed - it
does not predict the phenomenon under the given conditions, but we observed it
under said conditions.</p>

<p>This is the key feature of formal models: they allow us to unambiguously
assess whether a certain instantiation of a theory can capture a phenomenon <a href="https://www.andywills.info/assets/pdf/2012willspothos.pdf">(Wills &amp; Pothos, 2012)</a>.
We usually do this post-hoc (after the data has been analysed). We apply
some fitting technique to try to adapt the parameters of the model, so that
the model mimics human behaviour as close as possible.</p>

<p>The parameters will change the model‚Äôs behaviour in some sense, so we have to find
the ones which reproduce human behaviour as close as possible. 
The model‚Äôs behaviour will depend on not just what are the psychological processes
that it specifies, but also what parameters we give it, how those parameters
interact, and how those parameters tune the behaviour of
the model in a given experiment.</p>

<p>This goodness-of-fit approach has some limits. 
<a href="https://psycnet.apa.org/doi/10.1037/0033-295X.107.2.358">Roberts and Pashler (2000)</a>
rightly points out three limits of a goodness-of-fit approach:</p>

<ol>
  <li>A good fit <strong>does not tell us what the theory predicts.</strong></li>
  <li>Between-subject variability is not explained by a good fit.</li>
  <li>A priori likelihood that the theory will fit. <strong>It matters that the plausible outcomes are a small fraction of all possible outcomes.</strong></li>
</ol>

<p>This means that <strong>models predict multiple things</strong>. That is the point of psp -
even in the same experiment, <strong>models predict more than one thing. We should
probably know what the model (a formalization of a certain theory) predicts.</strong>
In my belief, that is how we should test whether the way we understand the
world accurately represents the word itself.</p>

<p>PSP allows us not only to find these predictions, but also to understand
how the model produces them, what behaviour of a model leads to a certain
prediction, how many different ways a model‚Äôs behaviour results in the same
prediction.
It can also tell us how big of a chunk a certain pattern makes up
in its behaviour (default behaviour vs. rare behaviour).</p>

<p>Another useful feature of PSP is that it allows to explore the whole parameter
space. All models will exhibit unexpected and unreliable 
behaviour if the parameters fall outside of certain bounds. It is also somewhat
problematic for implementations, as some functions like exponential functions
can easily get out of hand. Authors rarely provide a lower and upper bound
for all parameters in a given model. Parameter space partitioning allows us
to determine those boundaries efficiently.</p>

<h2 id="example">EXAMPLE</h2>

<p>In the remainder of this post, I will walk through the steps of using <code class="language-plaintext highlighter-rouge">psp</code>.
This walk-through will use a two parameter model. PSP will need to find 10 distinct
regions.</p>

<h3 id="install">INSTALL</h3>

<p>For the stable version:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">install.packages</span><span class="p">(</span><span class="s2">"psp"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>For the developmental version:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">devtools</span><span class="o">::</span><span class="n">install_github</span><span class="p">(</span><span class="s2">"lenarddome/psp"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<h3 id="model">MODEL</h3>

<p>Then we put together a model (essentially a model of a polytope), that
calculates the euclidean distance from a selected number of points. These
points are selected at random at the beginning and kept constant throughout
the simulation. In the original paper,
<a href="https://psycnet.apa.org/doi/10.1037/0033-295X.113.1.57">Pitt, Kim, Navarro and Myung (2006)</a>
used a hypercube to test the algorithm, here I will use a polytope. I choose
to use a polytope, because I want the regions to vary in size, compared to a hypercube
where the space is uniformly partitioned.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cd">#' euclidean distance</span><span class="w">
</span><span class="cd">#'</span><span class="w">
</span><span class="cd">#' @param a vector coordinate 1</span><span class="w">
</span><span class="cd">#' @param b vector coordinate 2</span><span class="w">
</span><span class="cd">#' @return euclidean distance between coordinates</span><span class="w">
</span><span class="n">euclidean</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">sum</span><span class="p">((</span><span class="n">a</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">))</span><span class="w">

</span><span class="c1"># define center points for the 10 regions in a two-dimensional space </span><span class="w">
</span><span class="n">positions</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kc">NULL</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nf">seq_len</span><span class="p">(</span><span class="m">2</span><span class="p">))</span><span class="w"> </span><span class="n">positions</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">positions</span><span class="p">,</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="m">500</span><span class="p">,</span><span class="w"> </span><span class="m">10</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>

<p>If we have those two, we could put together our model of a polytope.
We need to code our model, so it take sin a vector of parameters and
outputs a character vector. It doesn‚Äôt have to be a character vector.
It can also be a Boolean, or integers, but I am yet to test it with those.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cd">#' dummy polytope model to test the PSP function</span><span class="w">
</span><span class="cd">#' The model takes in a set of coordinates, calculates its distance from all</span><span class="w">
</span><span class="cd">#' all of available coordinates, then return closest region number.</span><span class="w">
</span><span class="cd">#' This model generalizes to n-dimensions</span><span class="w">
</span><span class="cd">#'</span><span class="w">
</span><span class="cd">#' @param x a vector of coordinates</span><span class="w">
</span><span class="cd">#' @return The number of the region as character</span><span class="w">
</span><span class="cd">#' @examples</span><span class="w">
</span><span class="cd">#' model(runif(5))</span><span class="w">
</span><span class="n">model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">par</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="n">areas</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kc">NULL</span><span class="w"> 
    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nf">seq_along</span><span class="p">(</span><span class="n">par</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="n">range</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">)</span><span class="w">
        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">%%</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="m">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
            </span><span class="n">range</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w">
        </span><span class="p">}</span><span class="w"> 
        </span><span class="n">areas</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">areas</span><span class="p">,</span><span class="w">
                       </span><span class="n">seq</span><span class="p">(</span><span class="n">range</span><span class="p">[</span><span class="m">1</span><span class="p">],</span><span class="w"> </span><span class="n">range</span><span class="p">[</span><span class="m">2</span><span class="p">],</span><span class="w"> </span><span class="n">length.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">)[</span><span class="n">positions</span><span class="p">[,</span><span class="n">i</span><span class="p">]])</span><span class="w">
    </span><span class="p">}</span><span class="w">
    </span><span class="n">dist</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">apply</span><span class="p">(</span><span class="n">areas</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="n">euclidean</span><span class="p">(</span><span class="n">par</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">))</span><span class="w">
    </span><span class="nf">return</span><span class="p">(</span><span class="nf">as.character</span><span class="p">(</span><span class="n">which.min</span><span class="p">(</span><span class="n">dist</span><span class="p">)))</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<h3 id="simulation">SIMULATION</h3>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">psp</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>Now we can let psp do its job. 
Here we run the MCMC for 400 iterations, but the partitioning
will stop if the population of all regions reach 300.
Note that we have to load our utility function into
the clusters, because psp_global will run parallel.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># run Parameter Space Partitioning with some default settings</span><span class="w">
</span><span class="n">out</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">psp_global</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">psp_control</span><span class="p">(</span><span class="n">lower</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">),</span><span class="w">
                                   </span><span class="n">upper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">),</span><span class="w">
                                   </span><span class="n">init</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">),</span><span class="w">
                                   </span><span class="n">radius</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">0.25</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">),</span><span class="w">
                                   </span><span class="n">pop</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">300</span><span class="p">,</span><span class="w">
                                   </span><span class="n">cluster_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"positions"</span><span class="p">,</span><span class="w">
                                                     </span><span class="s2">"euclidean"</span><span class="p">),</span><span class="w">
                                   </span><span class="n">iterations</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>

<p>This process produces us the following result:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">$</span><span class="n">ps_patterns</span><span class="w">

  </span><span class="m">1</span><span class="w">   </span><span class="m">2</span><span class="w">   </span><span class="m">3</span><span class="w">   </span><span class="m">4</span><span class="w">   </span><span class="m">5</span><span class="w">   </span><span class="m">6</span><span class="w">   </span><span class="m">7</span><span class="w">   </span><span class="m">8</span><span class="w">   </span><span class="m">9</span><span class="w">  </span><span class="m">10</span><span class="w">
</span><span class="m">300</span><span class="w"> </span><span class="m">344</span><span class="w"> </span><span class="m">317</span><span class="w"> </span><span class="m">306</span><span class="w"> </span><span class="m">359</span><span class="w"> </span><span class="m">358</span><span class="w"> </span><span class="m">307</span><span class="w"> </span><span class="m">396</span><span class="w"> </span><span class="m">416</span><span class="w"> </span><span class="m">397</span><span class="w">
</span></code></pre></div></div>

<p>In this case, psp_global stopped before it reached the 500th iteration, because
all regions reached at least 300 <code class="language-plaintext highlighter-rouge">pop</code>. We can also see that some regions have a
population larger than 300. This is because even though the sampling from that
regions stopped, new points can still be classed as members of those regions.</p>

<p>So PSP partitioned the parameter space into distinct disjointed regions, according
to what the model predicted.</p>

<p>This is how it looks under the hood in real time:</p>

<iframe width="800" height="600" src="https://www.youtube.com/embed/xkfKJO2ViWI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>Each colour is a separate region.</p>

<h3 id="amazing-but-what-now">AMAZING, BUT WHAT NOW?</h3>

<p>This was a simple model bearing no relevance to psychology - unless you are
one of the few believing that the brain has a geometry module or that learning
happens according to geometry.</p>

<p>The question is what we can do with the output now? A simple next step could
be <strong>calculating volume of the regions</strong>.</p>

<p>Alternatively, you can try to discover clusters of points in the parameter space
within regions and ordinal patterns. There might be many ways a model might behave
but still outputs the same result.</p>

<p>You can compare how many different qualitative outputs the model produces and
how many of those have been observed in humans. You might also try to figure out
when unobserved qualitative outputs occur according to the model.</p>

<h2 id="notes-for-the-curious">NOTES FOR THE CURIOUS</h2>

<p>I had some thoughts while trying to implement the algorithm. Turns out,
some of my concern was picked up by people other than me.</p>

<h3 id="volumes-will-not-be-included">VOLUMES [will not be included]</h3>

<p>Not feasible to implement a method that generalizes to n-dimensional polyhedra
or convex polytope. There are already packages out there that can do it. I would
leave it for the user. The method of calculating the volume/area of each region
should be an explicit choice the modeller makes.</p>

<h3 id="burn-in-will-not-be-implemented">BURN-IN [will not be implemented]</h3>

<p>If you have a decent starting point (e.g. parameters EXIT uses to produce inverse
base-rate effect, or ALCOVE best-fitting parameters for the Type I-VI problems),
burn-in is unnecessary.</p>

<p>I am also not sure why burn-in is necessary for parameter space partitioning.
It seems counter-intuitive to discard areas you explored in the parameter space
if you‚Äôd like to explore said parameter space. Here we have no target to reach
other than to fill in the whole space - unlike scenarios where you want
to optimize some point estimate like the mean of a distribution</p>

<p>One problem we might encounter is that <em>regions further away from our starting
jumping distribution will be under-sampled</em>. This could be avoided by increasing the number
of <code class="language-plaintext highlighter-rouge">iterations</code>, so the MCMC will sample long enough to adequately populate
those regions as well. One might also choose to decrease the radius to
sample from smaller areas surrounding the jumping distributions.</p>

<p>Resources to look through:</p>

<ul>
  <li>https://stats.stackexchange.com/questions/88819/mcmc-methods-burning-samples</li>
  <li>http://users.stat.umn.edu/%7Egeyer/mcmc/burn.html</li>
  <li>https://www.johndcook.com/blog/2016/01/25/mcmc-burn-in/</li>
</ul>

  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Lenard  Dome.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
